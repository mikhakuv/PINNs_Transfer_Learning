{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJ7LEEdITEKV"
   },
   "source": [
    "# Параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUQ4ZQbbFfKv",
    "outputId": "9a91e894-fd03-48fd-ad22-7e99a370fed8"
   },
   "outputs": [],
   "source": [
    "!pip install pyDOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7HDFnr8Ui_6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from collections import OrderedDict #упорядоченный словарь\n",
    "from pyDOE import lhs #функция, выбирающая значения для обучения на них нейросети\n",
    "import time\n",
    "np.random.seed(1234)\n",
    "if torch.cuda.is_available(): #можно сменить среду выполнения на gpu и обучение будет происходить быстрее\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "### Настраиваемые параметры\n",
    "exp_name=\"VT_1(10)\"\n",
    "source_exp_name=\"BL_1(10)\"\n",
    "alpha_value=0.20\n",
    "###\n",
    "\n",
    "if \"BL\" in exp_name:\n",
    "  basic_learning=True\n",
    "  weights_transfer=False\n",
    "  values_transfer=False\n",
    "if \"WT\" in exp_name:\n",
    "  basic_learning=False\n",
    "  weights_transfer=True\n",
    "  values_transfer=False\n",
    "if \"VT\" in exp_name:\n",
    "  basic_learning=False\n",
    "  weights_transfer=False\n",
    "  values_transfer=True\n",
    "\n",
    "try:\n",
    "    os.mkdir((f\"exp_{exp_name}\"))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "stats_file = open(f\"exp_{exp_name}/stats.txt\",\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ma6BrcHTSyyW"
   },
   "outputs": [],
   "source": [
    "#параметры области:\n",
    "x_0=-60\n",
    "x_1=40\n",
    "t_0=0\n",
    "t_1=20\n",
    "x_parts=1000 # разбиение по x\n",
    "t_parts=200 # разбиение по t\n",
    "#параметры начального условия:\n",
    "k_param=1\n",
    "w_param=0.88\n",
    "x0_param=-30\n",
    "th0_param=0\n",
    "alpha0_param=alpha_value\n",
    "#параметры уравнения:\n",
    "alpha=alpha_value\n",
    "beta=0\n",
    "\n",
    "def q(x,t):\n",
    "    mu=4*(k_param**2-w_param)\n",
    "    k_exp = np.exp(np.sqrt(mu)*(x - 2*k_param*t - x0_param))\n",
    "    f_com = ((mu*k_exp) / ((0.5*k_exp+1)**2 - k_exp*k_exp*alpha0_param*mu/3))**0.5\n",
    "    u = f_com*np.cos(k_param*x - w_param*t + th0_param)\n",
    "    v = f_com*np.sin(k_param*x - w_param*t + th0_param)\n",
    "    u=np.nan_to_num(u) #нужно на больших областях, когда на краях области появляются Nan\n",
    "    v=np.nan_to_num(v)\n",
    "    return u,v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSj6OaovBhEG"
   },
   "source": [
    "# PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lgsje_Ms8Vmr"
   },
   "outputs": [],
   "source": [
    "class SinActivation(torch.nn.Module): #кастомная функция активации - sin\n",
    "    def __init__(self):\n",
    "        super(SinActivation, self).__init__()\n",
    "        return\n",
    "    def forward(self, x):\n",
    "        return torch.sin(x)\n",
    "\n",
    "class DNN(torch.nn.Module): # нейросеть, в виде которой будет находиться решение\n",
    "    def __init__(self, layers): #принимает на вход массив целых чисел\n",
    "        super(DNN, self).__init__() #вызывает метод init(почему нельзя сделать это без super?)\n",
    "\n",
    "        self.depth = len(layers) - 1\n",
    "        self.activation = SinActivation #в качестве функции активации используется sin\n",
    "\n",
    "        layer_list = list() #список с весами и функциями активации для каждого слоя\n",
    "        for i in range(self.depth - 1):\n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1])) #каждые два слоя образуют двудольный граф\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "\n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1])) #нельзя сделать в цикле, потому что нет функции активации\n",
    "        )\n",
    "\n",
    "        layerDict = OrderedDict(layer_list) #сделали упорядоченный словарь, чтобы при использовании элементы выдавались в том порядке, в котором были добавлены\n",
    "\n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict) #задали архитектуру нейросети\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "\n",
    "class PhysicsInformedNN(): # PINN\n",
    "    def __init__(self, X_tl, u_tl, v_tl, X_uv, u, v, layers, alpha, beta):\n",
    "\n",
    "        self.X_tl = X_tl\n",
    "        self.u_tl = u_tl\n",
    "        self.v_tl = v_tl\n",
    "        self.X_uv = X_uv\n",
    "        self.u = u\n",
    "        self.v = v\n",
    "        # данные для обучения\n",
    "        if values_transfer:\n",
    "            #для value_transfer: (x_tl, t_tl, u, v)\n",
    "            idx = np.random.choice(self.X_tl.shape[0], N_vt, replace=False)\n",
    "            self.actual_x_tl = torch.tensor(self.X_tl[idx, 0:1], requires_grad=True).float().to(device)\n",
    "            self.actual_t_tl = torch.tensor(self.X_tl[idx, 1:2], requires_grad=True).float().to(device)\n",
    "            self.actual_u_tl = torch.tensor(self.u_tl[idx, :]).float().to(device)\n",
    "            self.actual_v_tl = torch.tensor(self.v_tl[idx, :]).float().to(device)\n",
    "        #для начальных и граничных условий: (x_uv, t_uv, u, v)\n",
    "        idx = np.random.choice(self.X_uv.shape[0], N_ib, replace=False)\n",
    "        self.actual_x_uv = torch.tensor(self.X_uv[idx, 0:1], requires_grad=True).float().to(device)\n",
    "        self.actual_t_uv = torch.tensor(self.X_uv[idx, 1:2], requires_grad=True).float().to(device)\n",
    "        self.actual_u = torch.tensor(self.u[idx, :]).float().to(device)\n",
    "        self.actual_v = torch.tensor(self.v[idx, :]).float().to(device)\n",
    "        #для уравнения: (x_f, t_f, f=0)\n",
    "        idx = np.random.choice(self.X_tl.shape[0], N_eq, replace=False)\n",
    "        self.actual_x_f = torch.tensor(self.X_tl[idx, 0:1], requires_grad=True).float().to(device)\n",
    "        self.actual_t_f = torch.tensor(self.X_tl[idx, 1:2], requires_grad=True).float().to(device)\n",
    "\n",
    "        # числовые коэффициенты в уравнении\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "        # модель\n",
    "        self.layers = layers\n",
    "        self.dnn = DNN(layers).to(device)\n",
    "\n",
    "        # оптимизатор - LBFGS, обучает с точностью до 1e-5 или пока разница в точности уменьшается больше, чем точность float(?)\n",
    "        self.optimizer = torch.optim.LBFGS(\n",
    "            self.dnn.parameters(),\n",
    "            lr=0.00001,\n",
    "            max_iter=50000,\n",
    "            max_eval=50000,\n",
    "            history_size=50,\n",
    "            tolerance_grad=1e-6,\n",
    "            tolerance_change=1.0 * np.finfo(float).eps,\n",
    "            #line_search_fn=\"strong_wolfe\"\n",
    "        )\n",
    "\n",
    "        self.adam = torch.optim.Adam(\n",
    "          self.dnn.parameters(),\n",
    "          lr=0.005,\n",
    "          betas=(0.9, 0.999),\n",
    "          eps=1e-08,\n",
    "          weight_decay=0,\n",
    "          amsgrad=False)\n",
    "\n",
    "        self.iter = 0\n",
    "\n",
    "    def net_uv(self, x, t): # вывод модели\n",
    "        u = self.dnn(torch.cat([x, t], dim=1))[:,0:1]\n",
    "        v = self.dnn(torch.cat([x, t], dim=1))[:,1:2]\n",
    "        return u, v\n",
    "\n",
    "    def net_f(self, x, t): #вывод  функции\n",
    "        \"\"\" The pytorch autograd version of calculating residual \"\"\"\n",
    "        u, v = self.net_uv(x, t)\n",
    "\n",
    "        u_t = torch.autograd.grad(\n",
    "            u, t,\n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0] #производая по t\n",
    "        u_x = torch.autograd.grad(\n",
    "            u, x,\n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0] #производная по x\n",
    "        u_xx = torch.autograd.grad(\n",
    "            u_x, x,\n",
    "            grad_outputs=torch.ones_like(u_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0] #вторая призводная по x\n",
    "\n",
    "        v_t = torch.autograd.grad(\n",
    "            v, t,\n",
    "            grad_outputs=torch.ones_like(v),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0] #производая по t\n",
    "        v_x = torch.autograd.grad(\n",
    "            v, x,\n",
    "            grad_outputs=torch.ones_like(v),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0] #производная по x\n",
    "        v_xx = torch.autograd.grad(\n",
    "            v_x, x,\n",
    "            grad_outputs=torch.ones_like(v_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0] #вторая призводная по x\n",
    "\n",
    "        f_u = u*(u**2 + v**2)*(-self.alpha*(u**2 + v**2) + self.beta*(u**2 + v**2)**2 + 1) + u_xx - v_t #это и есть действительная и коплексная части исходного уравнения\n",
    "        f_v = u_t + v*(u**2 + v**2)*(-self.alpha*(u**2 + v**2) + self.beta*(u**2 + v**2)**2 + 1) + v_xx #они получены путём подстановки q=u+i*v в него\n",
    "        return f_u, f_v\n",
    "\n",
    "    def loss_func(self): #функция потерь\n",
    "        self.optimizer.zero_grad() #обнуляет градиенты\n",
    "        if values_transfer and self.iter<=transfer_period: # учим удовлетворять значениям\n",
    "          u_pred, v_pred = self.net_uv(self.actual_x_tl, self.actual_t_tl)\n",
    "          loss_tl = torch.mean(((self.actual_u_tl - u_pred) ** 2 + (self.actual_v_tl - v_pred) ** 2)/2) #средний квадрат всех отклонений от известных значений\n",
    "          loss = loss_tl\n",
    "        else: # учим удовлетворять уравнению\n",
    "          u_pred, v_pred = self.net_uv(self.actual_x_uv, self.actual_t_uv)\n",
    "          f_u_pred, f_v_pred = self.net_f(self.actual_x_f, self.actual_t_f)\n",
    "          loss_uv = torch.mean(((self.actual_u - u_pred) ** 2 + (self.actual_v - v_pred) ** 2)/2) #средний квадрат всех отклонений от начальных и граничных условий\n",
    "          loss_f = torch.mean((f_u_pred ** 2 + f_v_pred ** 2)/2) #средний квадрат всех отклонений от условия\n",
    "          loss = loss_uv + loss_f\n",
    "\n",
    "        loss.backward()\n",
    "        self.iter += 1\n",
    "        if self.iter % 100 == 0: #каждые 100 итераций перегенерируем точки\n",
    "            idx = np.random.choice(self.X_uv.shape[0], N_ib, replace=False)\n",
    "            self.actual_x_uv = torch.tensor(self.X_uv[idx, 0:1], requires_grad=True).float().to(device)\n",
    "            self.actual_t_uv = torch.tensor(self.X_uv[idx, 1:2], requires_grad=True).float().to(device)\n",
    "            self.actual_u = torch.tensor(self.u[idx, :]).float().to(device)\n",
    "            self.actual_v = torch.tensor(self.v[idx, :]).float().to(device)\n",
    "            \n",
    "            idx = np.random.choice(self.X_tl.shape[0], N_eq, replace=False)\n",
    "            self.actual_x_f = torch.tensor(self.X_tl[idx, 0:1], requires_grad=True).float().to(device)\n",
    "            self.actual_t_f = torch.tensor(self.X_tl[idx, 1:2], requires_grad=True).float().to(device)\n",
    "            \n",
    "            if values_transfer:\n",
    "                idx = np.random.choice(self.X_tl.shape[0], N_vt, replace=False)\n",
    "                self.actual_x_tl = torch.tensor(self.X_tl[idx, 0:1], requires_grad=True).float().to(device)\n",
    "                self.actual_t_tl = torch.tensor(self.X_tl[idx, 1:2], requires_grad=True).float().to(device)\n",
    "                self.actual_u_tl = torch.tensor(self.u_tl[idx, :]).float().to(device)\n",
    "                self.actual_v_tl = torch.tensor(self.v_tl[idx, :]).float().to(device)\n",
    "\n",
    "        if self.iter % 1000 == 0:\n",
    "            if values_transfer and self.iter <= transfer_period:\n",
    "              print('Iter %d, Loss: %.5e' % (self.iter, loss.item()))\n",
    "            else:\n",
    "              print('Iter %d, Loss: %.5e, Loss_uv: %.5e, Loss_f: %.5e' % (self.iter, loss.item(), loss_uv.item(), loss_f.item()))\n",
    "            loss_array.append(loss.item()) #loss запоминаем для графика\n",
    "            iter_array.append(self.iter)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def train(self): #обучение\n",
    "        adam_iterations = 100000\n",
    "        if values_transfer:\n",
    "          adam_iterations += transfer_period\n",
    "        print('training started')\n",
    "        print('%d iterations of ADAM:' %adam_iterations)\n",
    "        self.dnn.train()\n",
    "        for i in range(adam_iterations): #во время тренировки производится 1000 шагов adam\n",
    "            if i % 100 == 0: self.adam.param_groups[0]['lr'] = 0.99*self.adam.param_groups[0]['lr'] #экспоненциальное уменьшение шага каждые 100 шагов\n",
    "            if values_transfer and i==transfer_period: self.adam.param_groups[0]['lr'] = 0.005\n",
    "            self.adam.step(self.loss_func)\n",
    "        #print('LBFGS:') #а дальше запускается lbfgs\n",
    "        #self.optimizer.step(self.loss_func)\n",
    "        print('Total iterations: %d + %d' %(adam_iterations, (self.iter-adam_iterations)))\n",
    "\n",
    "\n",
    "    def predict(self, X): #вывод нейросети и функции на входных данных\n",
    "        x = torch.tensor(X[:, 0:1], requires_grad=True).float().to(device)\n",
    "        t = torch.tensor(X[:, 1:2], requires_grad=True).float().to(device)\n",
    "\n",
    "        self.dnn.eval()\n",
    "        u, v = self.net_uv(x, t)\n",
    "        f_u, f_v = self.net_f(x, t)\n",
    "        u = u.detach().cpu().numpy()\n",
    "        v = v.detach().cpu().numpy()\n",
    "        f_u = f_u.detach().cpu().numpy()\n",
    "        f_v = f_v.detach().cpu().numpy()\n",
    "        return u, v, f_u, f_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmzI7WJKd4fO"
   },
   "outputs": [],
   "source": [
    "if weights_transfer:\n",
    "  raw_model = torch.load(f'model_{source_exp_name}.pth', map_location=device) #загружаем модель\n",
    "if values_transfer:\n",
    "  raw_data = pd.read_csv(f'data_{source_exp_name}.csv') #загружаем данные для обучения\n",
    "  raw_t_0=t_0\n",
    "  raw_t_1=t_1\n",
    "  raw_x_0=x_0\n",
    "  raw_x_1=x_1\n",
    "  raw_t_parts=t_parts\n",
    "  raw_x_parts=x_parts\n",
    "  raw_X = np.array(raw_data['x']).reshape(raw_t_parts,raw_x_parts)\n",
    "  raw_T = np.array(raw_data['t']).reshape(raw_t_parts,raw_x_parts)\n",
    "  raw_U = np.array(raw_data['pred_u']).reshape(raw_t_parts,raw_x_parts)\n",
    "  raw_V = np.array(raw_data['pred_v']).reshape(raw_t_parts,raw_x_parts)\n",
    "  raw_Q_abs = np.array(raw_data['pred_h']).reshape(raw_t_parts,raw_x_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LJ1A5DGbEmFY"
   },
   "outputs": [],
   "source": [
    "N_ib = 1000 # число точек, обучающих принимать граничные значения\n",
    "N_eq = 50000 # число точек, обучающих удовлетворять уравнению\n",
    "N_vt = 80000 # число точек, обучающих принимать значения предыдущей модели\n",
    "layers = [2, 50, 50, 50, 2] # 2 входа, 2 выхода и 3 слоя по 50 нейронов\n",
    "transfer_period = 20000\n",
    "x = np.linspace(x_0, x_1, x_parts)\n",
    "t = np.linspace(t_0, t_1, t_parts)\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "Exact_q=q(X,T)[0] + 1j*q(X,T)[1]\n",
    "Exact_u=np.real(Exact_q)\n",
    "Exact_v=np.imag(Exact_q)\n",
    "Exact_q_abs = np.abs(Exact_q)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_star = Exact_u.flatten()[:,None]\n",
    "v_star = Exact_v.flatten()[:,None]\n",
    "\n",
    "# границы области\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "\n",
    "# для обучения берём только данные на границах области(граничные условия по сути)\n",
    "xx1 = np.hstack((X[0:1,:].T, T[0:1,:].T)) #(x,t_0)\n",
    "uu1 = Exact_u[0:1,:].T\n",
    "vv1 = Exact_v[0:1,:].T\n",
    "xx2 = np.hstack((X[:,0:1], T[:,0:1])) #(x_0,t)\n",
    "uu2 = np.zeros((t_parts,1)) #граничные условия поставил 0 в соответствии с требованиями\n",
    "vv2 = np.zeros((t_parts,1))\n",
    "xx3 = np.hstack((X[:,-1:], T[:,-1:])) #(x_1,t)\n",
    "uu3 = np.zeros((t_parts,1))\n",
    "vv3 = np.zeros((t_parts,1))\n",
    "\n",
    "X_uv_train = np.vstack([xx1, xx2, xx3]) #данные для тренировки в точках на границе\n",
    "u_train = np.vstack([uu1, uu2, uu3])\n",
    "v_train = np.vstack([vv1, vv2, vv3])\n",
    "#X_f_train = lb + (ub-lb)*lhs(2, N_eq) #данные для тренировки в случайных точкам из области\n",
    "#X_f_train = np.vstack((X_f_train, X_uv_train)) #добавим к ним ещё и точки на границе, там f тоже 0\n",
    "X_f_train =  X_star #сети передадим все имеющиеся точки, в процессе обучения будет выбираться набор из N_eq\n",
    "\n",
    "#idx = np.random.choice(X_uv_train.shape[0], N_ib, replace=False) #выберем из точек на границе только N_ib\n",
    "#X_uv_train = X_uv_train[idx, :]\n",
    "#u_train = u_train[idx,:]\n",
    "#v_train = v_train[idx,:]\n",
    "\n",
    "loss_array = [] #массив с loss в процессе обучения\n",
    "iter_array = [] #итерации с шагом 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VehkLJZR635n"
   },
   "outputs": [],
   "source": [
    "if values_transfer:\n",
    "  Q_truth=q(raw_X,raw_T)[0]+1j*q(raw_X,raw_T)[1] #за правильные значения берутся значения функции при ТЕКУЩЕМ alpha\n",
    "  U_truth=np.real(Q_truth)\n",
    "  V_truth=np.imag(Q_truth)\n",
    "  Q_abs_truth=np.abs(Q_truth)\n",
    "\n",
    "  fig, axs = plt.subplots(3, 3, figsize=(21,10), dpi=300)\n",
    "\n",
    "  for ax in axs.flat:\n",
    "      ax.set(xlabel='$t$', ylabel='$x$')\n",
    "\n",
    "  for ax in axs.flat:\n",
    "      ax.label_outer()\n",
    "\n",
    "  q_abs_min, q_abs_max = 0, np.abs(Q_abs_truth).max()\n",
    "  c = axs[0,0].pcolormesh(raw_T, raw_X, Q_abs_truth, cmap='BuPu', vmin=q_abs_min, vmax=q_abs_max)\n",
    "  axs[0,0].set_title('$|q_{truth}|(x,t)$')\n",
    "  axs[0,0].axis([t_0, t_1, x_0, x_1])\n",
    "  fig.colorbar(c, ax=axs[0,0])\n",
    "\n",
    "  u_min, u_max = -np.abs(U_truth).max(), np.abs(U_truth).max()\n",
    "  c = axs[0,1].pcolormesh(raw_T, raw_X, U_truth, cmap='RdBu', vmin=u_min, vmax=u_max)\n",
    "  axs[0,1].set_title('$u_{truth}(x,t)$')\n",
    "  axs[0,1].axis([t_0, t_1, x_0, x_1])\n",
    "  fig.colorbar(c, ax=axs[0,1])\n",
    "\n",
    "  c = axs[0,2].pcolormesh(raw_T, raw_X, V_truth, cmap='RdBu', vmin=u_min, vmax=u_max)\n",
    "  axs[0,2].set_title('$v_{truth}(x,t)$')\n",
    "  axs[0,2].axis([t_0, t_1, x_0, x_1])\n",
    "  fig.colorbar(c, ax=axs[0,2])\n",
    "\n",
    "\n",
    "  #q_abs_min, q_abs_max = 0, np.abs(Q_abs_calc).max()\n",
    "  c = axs[1,0].pcolormesh(raw_T, raw_X, raw_Q_abs, cmap='BuPu', vmin=q_abs_min, vmax=q_abs_max)\n",
    "  axs[1,0].set_title('$|q_{pred}|(x,t)$')\n",
    "  axs[1,0].axis([t_0, t_1, x_0, x_1])\n",
    "  fig.colorbar(c, ax=axs[1,0])\n",
    "\n",
    "  #u_min, u_max = -np.abs(U_calc).max(), np.abs(U_calc).max()\n",
    "  c = axs[1,1].pcolormesh(raw_T, raw_X, raw_U, cmap='RdBu', vmin=u_min, vmax=u_max)\n",
    "  axs[1,1].set_title('$u_{pred}(x,t)$')\n",
    "  axs[1,1].axis([t_0, t_1, x_0, x_1])\n",
    "  fig.colorbar(c, ax=axs[1,1])\n",
    "\n",
    "  c = axs[1,2].pcolormesh(raw_T, raw_X, raw_V, cmap='RdBu', vmin=u_min, vmax=u_max)\n",
    "  axs[1,2].set_title('$v_{pred}(x,t)$')\n",
    "  axs[1,2].axis([t_0, t_1, x_0, x_1])\n",
    "  fig.colorbar(c, ax=axs[1,2])\n",
    "\n",
    "\n",
    "  U_diff = np.abs(U_truth-raw_U)\n",
    "  V_diff = np.abs(V_truth-raw_V)\n",
    "  Q_abs_diff = np.abs(Q_abs_truth-raw_Q_abs)\n",
    "\n",
    "  q_abs_min, q_abs_max = 0, np.abs(Q_abs_diff).max()\n",
    "  c = axs[2,0].pcolormesh(raw_T, raw_X, Q_abs_diff, cmap='Reds', vmin=q_abs_min, vmax=q_abs_max)\n",
    "  axs[2,0].set_title('$||q_{truth}|-|q_{pred}||(x,t)$')\n",
    "  axs[2,0].axis([t_0, t_1, x_0, x_1])\n",
    "  fig.colorbar(c, ax=axs[2,0])\n",
    "\n",
    "  u_min, u_max = U_diff.min(), U_diff.max()\n",
    "  c = axs[2,1].pcolormesh(raw_T, raw_X, U_diff, cmap='Reds', vmin=u_min, vmax=u_max)\n",
    "  axs[2,1].set_title('$|u_{truth}-u_{pred}|(x,t)$')\n",
    "  axs[2,1].axis([t_0, t_1, x_0, x_1])\n",
    "  fig.colorbar(c, ax=axs[2,1])\n",
    "\n",
    "  c = axs[2,2].pcolormesh(raw_T, raw_X, V_diff, cmap='Reds', vmin=u_min, vmax=u_max)\n",
    "  axs[2,2].set_title('$|v_{truth}-v_{pred}|(x,t)$')\n",
    "  axs[2,2].axis([t_0, t_1, x_0, x_1])\n",
    "  fig.colorbar(c, ax=axs[2,2])\n",
    "\n",
    "  plt.savefig(f\"exp_{exp_name}/raw.png\")\n",
    "  plt.show()\n",
    "\n",
    "if weights_transfer:\n",
    "  raw_U, raw_V, _, _ = raw_model.predict(X_star)\n",
    "  raw_U = raw_U.reshape(t_parts, x_parts)\n",
    "  raw_V = raw_V.reshape(t_parts, x_parts)\n",
    "  raw_Q_abs = (raw_U**2 + raw_V**2)**0.5\n",
    "  U_truth = Exact_u\n",
    "  V_truth = Exact_v\n",
    "  Q_abs_truth = (U_truth**2 + V_truth**2)**0.5\n",
    "\n",
    "\n",
    "  fig, axs = plt.subplots(3, 3, figsize=(21,10), dpi=300)\n",
    "\n",
    "  for ax in axs.flat:\n",
    "      ax.set(xlabel='$t$', ylabel='$x$')\n",
    "\n",
    "  for ax in axs.flat:\n",
    "      ax.label_outer()\n",
    "\n",
    "  q_abs_min, q_abs_max = 0, np.abs(Q_abs_truth).max()\n",
    "  c = axs[0,0].pcolormesh(T, X, Q_abs_truth, cmap='BuPu', vmin=q_abs_min, vmax=q_abs_max)\n",
    "  axs[0,0].set_title('$|q_{truth}|(x,t)$')\n",
    "  axs[0,0].axis([t_0, t_1, x_0, x_1])\n",
    "  fig.colorbar(c, ax=axs[0,0])\n",
    "\n",
    "  u_min, u_max = -np.abs(U_truth).max(), np.abs(U_truth).max()\n",
    "  c = axs[0,1].pcolormesh(T, X, U_truth, cmap='RdBu', vmin=u_min, vmax=u_max)\n",
    "  axs[0,1].set_title('$u_{truth}(x,t)$')\n",
    "  axs[0,1].axis([t_0, t_1, x_0, x_1])\n",
    "  fig.colorbar(c, ax=axs[0,1])\n",
    "\n",
    "  c = axs[0,2].pcolormesh(T, X, V_truth, cmap='RdBu', vmin=u_min, vmax=u_max)\n",
    "  axs[0,2].set_title('$v_{truth}(x,t)$')\n",
    "  axs[0,2].axis([t_0, t_1, x_0, x_1])\n",
    "  fig.colorbar(c, ax=axs[0,2])\n",
    "\n",
    "\n",
    "  #q_abs_min, q_abs_max = 0, np.abs(Q_abs_calc).max()\n",
    "  c = axs[1,0].pcolormesh(T, X, raw_Q_abs, cmap='BuPu', vmin=q_abs_min, vmax=q_abs_max)\n",
    "  axs[1,0].set_title('$|q_{pred}|(x,t)$')\n",
    "  axs[1,0].axis([t_0, t_1, x_0, x_1])\n",
    "  fig.colorbar(c, ax=axs[1,0])\n",
    "\n",
    "  #u_min, u_max = -np.abs(U_calc).max(), np.abs(U_calc).max()\n",
    "  c = axs[1,1].pcolormesh(T, X, raw_U, cmap='RdBu', vmin=u_min, vmax=u_max)\n",
    "  axs[1,1].set_title('$u_{pred}(x,t)$')\n",
    "  axs[1,1].axis([t_0, t_1, x_0, x_1])\n",
    "  fig.colorbar(c, ax=axs[1,1])\n",
    "\n",
    "  c = axs[1,2].pcolormesh(T, X, raw_V, cmap='RdBu', vmin=u_min, vmax=u_max)\n",
    "  axs[1,2].set_title('$v_{pred}(x,t)$')\n",
    "  axs[1,2].axis([t_0, t_1, x_0, x_1])\n",
    "  fig.colorbar(c, ax=axs[1,2])\n",
    "\n",
    "\n",
    "  U_diff = np.abs(U_truth-raw_U)\n",
    "  V_diff = np.abs(V_truth-raw_V)\n",
    "  Q_abs_diff = np.abs(Q_abs_truth-raw_Q_abs)\n",
    "\n",
    "  q_abs_min, q_abs_max = 0, np.abs(Q_abs_diff).max()\n",
    "  c = axs[2,0].pcolormesh(T, X, Q_abs_diff, cmap='Reds', vmin=q_abs_min, vmax=q_abs_max)\n",
    "  axs[2,0].set_title('$||q_{truth}|-|q_{pred}||(x,t)$')\n",
    "  axs[2,0].axis([t_0, t_1, x_0, x_1])\n",
    "  fig.colorbar(c, ax=axs[2,0])\n",
    "\n",
    "  u_min, u_max = U_diff.min(), U_diff.max()\n",
    "  c = axs[2,1].pcolormesh(T, X, U_diff, cmap='Reds', vmin=u_min, vmax=u_max)\n",
    "  axs[2,1].set_title('$|u_{truth}-u_{pred}|(x,t)$')\n",
    "  axs[2,1].axis([t_0, t_1, x_0, x_1])\n",
    "  fig.colorbar(c, ax=axs[2,1])\n",
    "\n",
    "  c = axs[2,2].pcolormesh(T, X, V_diff, cmap='Reds', vmin=u_min, vmax=u_max)\n",
    "  axs[2,2].set_title('$|v_{truth}-v_{pred}|(x,t)$')\n",
    "  axs[2,2].axis([t_0, t_1, x_0, x_1])\n",
    "  fig.colorbar(c, ax=axs[2,2])\n",
    "\n",
    "  plt.savefig(f\"exp_{exp_name}/raw.png\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JLkxYAOaLEHB"
   },
   "outputs": [],
   "source": [
    "if weights_transfer or values_transfer:\n",
    "  mse_q = np.mean((Q_abs_truth.flatten() - raw_Q_abs.flatten())**2) #средний квадрат разности модулей\n",
    "  rel_h = np.linalg.norm(Q_abs_truth.flatten() - raw_Q_abs.flatten(), 2)/np.linalg.norm(Q_abs_truth.flatten(), 2) #отношение нормы разности модулей к норме модуля, принимает значения от 0 до 1, чем ближе к 0 тем лучше\n",
    "  print(f'MSE_q: {mse_q:.3e}, Rel_h: {rel_h:.3e}')\n",
    "  stats_file.write(f'Result of source data -- MSE_q: {mse_q:.5e}, Rel_h: {rel_h:.5e}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#штука сверху выведет итоговое время выполнения\n",
    "if basic_learning:\n",
    "  model = PhysicsInformedNN(X_f_train, _, _, X_uv_train, u_train, v_train, layers, alpha, beta)\n",
    "if weights_transfer:\n",
    "  model = PhysicsInformedNN(X_f_train, _, _, X_uv_train, u_train, v_train, layers, alpha, beta)\n",
    "  model.dnn.load_state_dict(raw_model.dnn.state_dict())\n",
    "if values_transfer:\n",
    "  raw_XT = np.hstack([raw_X.flatten()[:,None],raw_T.flatten()[:,None]])\n",
    "  raw_U = raw_U.flatten()[:,None]\n",
    "  raw_V = raw_V.flatten()[:,None]\n",
    "  #idx = np.random.choice(raw_XT.shape[0], N_eq, replace=False)\n",
    "  #raw_XT = raw_XT[idx,:]\n",
    "  #raw_U = (raw_U.flatten()[:,None])[idx,:]\n",
    "  #raw_V = (raw_V.flatten()[:,None])[idx,:]\n",
    "  model = PhysicsInformedNN(raw_XT, raw_U, raw_V, X_uv_train, u_train, v_train, layers, alpha, beta)\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "rzYOXMmdhsOW",
    "outputId": "7a2b4189-836d-4773-85fe-16b986749d8b"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.plot(np.array(iter_array), np.array(loss_array))\n",
    "plt.ylim(0,5e-6)\n",
    "plt.title('loss(iter)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZKDmotVQ4b13"
   },
   "outputs": [],
   "source": [
    "torch.save(model, f'model_{exp_name}.pth') #сохраняем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load(f'model_BL_2.pth', map_location=device) #загружаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbOX2RRH35K0"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    u_pred, v_pred, f_u_pred, f_v_pred = model.predict(X_star)\n",
    "except:\n",
    "    print('Data was separated')\n",
    "    batch_size = 10000\n",
    "    batches = X_star.shape[0]//batch_size\n",
    "    u_pred=np.zeros(0)\n",
    "    v_pred=np.zeros(0)\n",
    "    for i in range(0, batches):\n",
    "        if i != batches:\n",
    "            u_batch, v_batch, f_u_batch, f_u_batch = model.predict(X_star[i*batch_size:(i+1)*batch_size,:])\n",
    "        else:\n",
    "            u_batch, v_batch, f_u_batch, f_u_batch = model.predict(X_star[i*batch_size:-1,:])\n",
    "        u_pred = np.append(u_pred, u_batch)  \n",
    "        v_pred = np.append(v_pred, v_batch)\n",
    "    u_pred = np.expand_dims(u_pred, 1)\n",
    "    v_pred = np.expand_dims(v_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xi4EUflYZxAB",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_U = u_pred.reshape(t_parts, x_parts)\n",
    "final_V = v_pred.reshape(t_parts, x_parts)\n",
    "final_Q_abs = (final_U**2 + final_V**2)**0.5\n",
    "\n",
    "Q_truth=q(X,T)[0]+1j*q(X,T)[1]\n",
    "U_truth=np.real(Q_truth)\n",
    "V_truth=np.imag(Q_truth)\n",
    "Q_abs_truth=np.abs(Q_truth)\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(21,10), dpi=300)\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='$t$', ylabel='$x$')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "q_abs_min, q_abs_max = 0, np.abs(Q_abs_truth).max()\n",
    "c = axs[0,0].pcolormesh(T, X, Q_abs_truth, cmap='BuPu', vmin=q_abs_min, vmax=q_abs_max)\n",
    "axs[0,0].set_title('$|q_{truth}|(x,t)$')\n",
    "axs[0,0].axis([t_0, t_1, x_0, x_1])\n",
    "fig.colorbar(c, ax=axs[0,0])\n",
    "\n",
    "u_min, u_max = -np.abs(U_truth).max(), np.abs(U_truth).max()\n",
    "c = axs[0,1].pcolormesh(T, X, U_truth, cmap='RdBu', vmin=u_min, vmax=u_max)\n",
    "axs[0,1].set_title('$u_{truth}(x,t)$')\n",
    "axs[0,1].axis([t_0, t_1, x_0, x_1])\n",
    "fig.colorbar(c, ax=axs[0,1])\n",
    "\n",
    "c = axs[0,2].pcolormesh(T, X, V_truth, cmap='RdBu', vmin=u_min, vmax=u_max)\n",
    "axs[0,2].set_title('$v_{truth}(x,t)$')\n",
    "axs[0,2].axis([t_0, t_1, x_0, x_1])\n",
    "fig.colorbar(c, ax=axs[0,2])\n",
    "\n",
    "\n",
    "#q_abs_min, q_abs_max = 0, np.abs(Q_abs_calc).max()\n",
    "c = axs[1,0].pcolormesh(T, X, final_Q_abs, cmap='BuPu', vmin=q_abs_min, vmax=q_abs_max)\n",
    "axs[1,0].set_title('$|q_{pred}|(x,t)$')\n",
    "axs[1,0].axis([t_0, t_1, x_0, x_1])\n",
    "fig.colorbar(c, ax=axs[1,0])\n",
    "\n",
    "#u_min, u_max = -np.abs(U_calc).max(), np.abs(U_calc).max()\n",
    "c = axs[1,1].pcolormesh(T, X, final_U, cmap='RdBu', vmin=u_min, vmax=u_max)\n",
    "axs[1,1].set_title('$u_{pred}(x,t)$')\n",
    "axs[1,1].axis([t_0, t_1, x_0, x_1])\n",
    "fig.colorbar(c, ax=axs[1,1])\n",
    "\n",
    "c = axs[1,2].pcolormesh(T, X, final_V, cmap='RdBu', vmin=u_min, vmax=u_max)\n",
    "axs[1,2].set_title('$v_{pred}(x,t)$')\n",
    "axs[1,2].axis([t_0, t_1, x_0, x_1])\n",
    "fig.colorbar(c, ax=axs[1,2])\n",
    "\n",
    "\n",
    "U_diff = np.abs(U_truth-final_U)\n",
    "V_diff = np.abs(V_truth-final_V)\n",
    "Q_abs_diff = np.abs(Q_abs_truth-final_Q_abs)\n",
    "\n",
    "q_abs_min, q_abs_max = 0, np.abs(Q_abs_diff).max()\n",
    "c = axs[2,0].pcolormesh(T, X, Q_abs_diff, cmap='Reds', vmin=q_abs_min, vmax=q_abs_max)\n",
    "axs[2,0].set_title('$||q_{truth}|-|q_{pred}||(x,t)$')\n",
    "axs[2,0].axis([t_0, t_1, x_0, x_1])\n",
    "fig.colorbar(c, ax=axs[2,0])\n",
    "\n",
    "u_min, u_max = U_diff.min(), U_diff.max()\n",
    "c = axs[2,1].pcolormesh(T, X, U_diff, cmap='Reds', vmin=u_min, vmax=u_max)\n",
    "axs[2,1].set_title('$|u_{truth}-u_{pred}|(x,t)$')\n",
    "axs[2,1].axis([t_0, t_1, x_0, x_1])\n",
    "fig.colorbar(c, ax=axs[2,1])\n",
    "\n",
    "c = axs[2,2].pcolormesh(T, X, V_diff, cmap='Reds', vmin=u_min, vmax=u_max)\n",
    "axs[2,2].set_title('$|v_{truth}-v_{pred}|(x,t)$')\n",
    "axs[2,2].axis([t_0, t_1, x_0, x_1])\n",
    "fig.colorbar(c, ax=axs[2,2])\n",
    "\n",
    "plt.savefig(f\"exp_{exp_name}/enhanced.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XEzr8EiV8Vq"
   },
   "source": [
    "# Результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LTWKsN5tpOLn"
   },
   "outputs": [],
   "source": [
    "mse_q = np.mean((Q_abs_truth.flatten() - final_Q_abs.flatten())**2) #средний квадрат разности модулей\n",
    "rel_h = np.linalg.norm(Q_abs_truth.flatten() - final_Q_abs.flatten(), 2)/np.linalg.norm(Q_abs_truth.flatten(), 2)\n",
    "print(f'MSE_q: {mse_q:.3e}, Rel_h: {rel_h:.3e}')\n",
    "stats_file.write(f'Final result -- MSE_q: {mse_q:.5e}, Rel_h: {rel_h:.5e}\\n')\n",
    "stats_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2NNL5n1u635w"
   },
   "outputs": [],
   "source": [
    "#сохраняем результаты в таблицу\n",
    "x_star = X.flatten()[:,None]\n",
    "t_star = T.flatten()[:,None]\n",
    "u_star = U_truth.flatten()[:,None]\n",
    "v_star = V_truth.flatten()[:,None]\n",
    "q_abs_star = Q_abs_truth.flatten()[:,None]\n",
    "q_abs_pred = (u_pred**2 + v_pred**2)**0.5\n",
    "\n",
    "data = pd.DataFrame({'x': x_star[:,0],\n",
    "                     't': t_star[:,0],\n",
    "                     'true_u': u_star[:,0],\n",
    "                     'true_v': v_star[:,0],\n",
    "                     'true_h': q_abs_star[:,0],\n",
    "                     'pred_u': u_pred[:,0],\n",
    "                     'pred_v': v_pred[:,0],\n",
    "                     'pred_h': q_abs_pred[:,0]})\n",
    "data.to_csv((f\"data_{exp_name}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
